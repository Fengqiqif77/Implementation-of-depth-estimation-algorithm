# 周报  

## 一、放假至1月12日  

  + 主要工作内容与成果：  
  
                    1、完成开题报告与任务书  
  
                    2、翻译参考文献  
                    
                    3、查阅资料，了解学习相关知识

## 二、1月12日至2月9日
   
   + 主要工作与成果：
             
                1、学习了有关深度学习的深度优化、梯度、神经网络的基本知识

                2、了解CNN的经典架构，及他们之间的优劣
 
                3、了解深度学习软件的框架，重点学习了PyTorch的相关知识

   + 下一步工作计划：

                继续学习RNN的相关知识，用PyTorch搭建一个小框架熟悉python语言
              
## 三、2月9日至2月16日

  + 主要工作与成果：
  
             安装pytorch
             
  + 遇到的的问题：
   
              1、直接安装pytorch速度慢，好几次中途停止，安装失败
              
              2、利用清华源镜像安装，速度稍微快一些，但是由于网速较慢，总是发生HTTP的报错，重试几次后终于安装成果
              
              3、不能成功导入torch包
                 （电脑上有两个版本的python，pytorch只支持3以上版本，将python2.7卸载后，成功导入torch）
                 
               4、torch.cuda报错（没有实现安装驱动）
               
## 四、2月17至3月1日

  + 主要成果：安装cuda及cuDNN
  
  + 遇到问题：1、CUDA driver version is insufficient for CUDA runtime version
                原因：CUDA驱动版本不满足CUDA运行版本。
                
 # 0302
 
   有了较为明确的中期目标，感觉更有动力了
   连接上了实验室的服务器，fighting
   
 # 0303
 
   看新论文和代码，有点懵
   
 # 0305
   重新看了下convLSTM的论文，和新论文做了下对比，我要实现的方法应该就是被称作encoderlstm的模型
   
   [convlstm] (https://www.dazhuanlan.com/2019/10/01/5d92fff8b9457/)
   
   补了下encoder-decoder网络结构的知识
   
   [encoder-decoder] (https://blog.csdn.net/xbinworld/article/details/54605408)
   
  # 0306
  认真学习了一下Dispnet网络相关知识
  （https://blog.csdn.net/kongfy4307/article/details/75212800）
  
  看开源代码，主要仔细看了encoderlstm的模型
  
  slim.arg_scope  设置参数
  
  slim.conv2d 做卷积（输入图像，滤波器个数，滤波器大小，步长，范围）
  cnv1  = slim.conv2d(current_input, 32,  [3, 3], stride=2, scope='cnv1')
  torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')

   # 0307
 无法导入torch包，最开始一直以为是路径配置的问题，弄了好久，后面问了老师才知道是没有激活环境的原因
 进入虚拟环境TestEnv后，输入source activate TestEnv
 激活环境之后，成功导入torch包啦~~

  # 0308
  今天先看了两篇论文，今天觉得我要实现的网络和encoderlstm还是有区别，询问学姐后确定他们两个不是完全一样的
  本来准备直接开始修改代码，发现自己的预备知识还是不足，修改起来很费劲
  所以先跑了几遍手写数字识别的网络来熟悉深度学习网络的框架，网上教程挺多的，基本上没有遇到什么困难，
  然后，我找到两份分别由pytorch和tensorflow写的代码，做比较
  
  # 0309
  今天是周一，需要开会，开会确定了未来一周的工作
  然后建立了新的虚拟环境
  
  # 0310
  安装好需要的包，
  运行手写识别数字程序发现，虽然可以成功导入tensorflow，但是却无法按照官网的教程成功下载minist，导入其他tensorflow内的包时内会报错
  上网查了下后，发现是tensorflow高版本2.0版缺少一些文件，导致导入失败，卸载高版本，重新安装低版本后，问题解决
  但是，运用matplotlib绘图时，图片并不会显示
  
  
  # 0311
  今天先直接跑了下开源代码，warning太多，而且有报错
  于是开始解决昨天的，显示图片问题
  网上的大多数解决方案都是针对远程服务器的GUI界面显示在本地的，
  针对没有图形界面服务器，网上给出的解决方案是将绘制好的图片存储到指定路径，然后打开图片查看
  
  同样，我还是用手写数字识别的网络进行测试，成功得到了一张图片
  
  但是总觉得这些改动很奇怪，而且每次都这样操作的话，很麻烦，
  继续查资料后发现，这个方法将matplotlib后端改成AGG，强制不能交互式查看图片，只能将图片保存后查看
  我将新加的代码注释后，直接使用plt.show()图片就显示出来了？？！！那我昨天遇到的问题是咋回事？
  ：
 
  # 0313
  下载KITTI训练集，训练和测试这两者的区别和功能不是很清楚，乘着下载训练集的时候，看了资料，了解了两者的作用
  在真正运行代码前还需要对数据进行预处理，
  开源代码中已有预处理的代码
  
  # 0314 
  昨天训练集没有下完，今天接着下
  然后看了下代码运行后的报错和warning，
  大多数warning都是某某库已弃用，请换用新库，使用tensorflow2.0版本，但是由于需要和服务器cuda版本一致，所以还是继续沿用1.x版本
  
  然后在和媛媛讨论的时候，发现她遇到一个和我一样的报错，dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/lib64
后面发现，我们安装的tf缺少了部分包，导致报错，卸载tf后重新安装，安装包齐全，没有再报错

训练集是直接从学姐那里拷贝到自己的虚拟环境中，但是总在拷贝过程中中断

再次修改文件路径后运行开源代码，报错，tensorflow.python.framework.errors_impl.PermissionDeniedError: /playpen1; Permission denied
没有写入权限的报错，查看代码后发现是训练的时候报错。修改该部分的路径，从相对路径改为绝对路径，再次运行，没有报错

## ~~~
# 0317
代码能跑起来，但是GPU占有率非常低才有个位数的占有率，最终输出的结果也全为0
暂未解决= =、

# 0319
这两天一直在解决这个问题
最开始一直以为是我没有正确修改代码的问题，可能是某个路径没有填对或者是参数没加上
然后发现，代码训练是按照train文本文件中顺序进行读取的，服务器的KITTI数据集是按照时间存在不同的文件夹里，而train文本中有不同的时间序列，可能是这里出了问题，导致读取不到部分文件，因为文件比较大，重新整理比较耗费时间和内存，我就修改了train文本，只留下2011-09-26-XXX的文本，然后将路径指到该日期的文件夹下

运行代码后，运行结果没有变化，还是有错误

然后我开始单步调试，发现这其实是一个溢出错误tf.errors.OutOfRangeError，代码中处理了这个错误并抛出

盯着代码看了几个小时后，猛然发现，generate_kitti_train_datasets这个文件相对独立，其他的py文件都没有导入它
这个文件的代码主要的功能是加载数据，生成一个新的文件，而这个新文件需要在后面的训练中使用到
因为缺少这个新文件，所以才会出现溢出错误

应该先运行这个代码，然后再跑main

代码跑了很长时间，然后突然报错中止，服务器的连接也断了Process finished with exit code -1
调试后发现代码中加入了import pdb;pdb.set_trace()，代码运行到这里就会暂停到这里，报错是因为在中断的时候和服务器断连了
将此句注释后，可以继续运行

然后还是路径问题，需要的正确路径为/media/hp/MITC-GPU-01/kitti_data/2011_09_26/calib_imu_to_velo.txt
当我把kitti-path路径改为/media/hp/MITC-GPU-01/kitti_data/时，报错FileNotFoundError: [Errno 2] No such file or directory: '/media/hp/MITC-GPU-01/kitti_data/calib_imu_to_velo.txt'
把kitti-path路径改为/media/hp/MITC-GPU-01/kitti_data/2011_09_26/时，报错FileNotFoundError: [Errno 2] No such file or directory: '/media/hp/MITC-GPU-01/kitti_data/2011_09_26/2011_09_26/calib_imu_to_velo.txt'

# 0321
运行预处理代码还是会报同样的错误，但是有所需要的类型文件生成
我直接运行main文件，依然是同样的问题，并未解决
查看了新生成文件的大小，发现它们都是空文件，大小为0

重新看了一下没修改过的源代码，发现是depth_path的路径没有指对，重新修改该路径后，
部分文件可以正常操作但是，有部分不行。例如，序列名称为2011_09_26_drive_0002_sync的数据集不能成功进行预处理，但是2011_09_26_drive_0009_sync却可以，
然后我发现，可以正常处理的数据集序列是同时存在于kitti里和depth文件夹中，反之，不可以正常处理的数据集序列只存在于一个文件夹中，
据此，比较简单的解决办法是修改txt文件，选择同时存在于两个文件夹的序列进行预处理

# 0322
了解KITTI数据集的组成，
  标定文件：calib_cam_to_cam.txt，calib_imu_to_velo.txt，calib_velo_to_cam.txt
    （1）calib_cam_to_cam.txt(相机到相机的标定)：
        - S_xx：1x2  矫正前的图像xx的大小

        - K_xx：3x3 矫正前摄像机xx的校准矩阵

        - D_xx：1x5  矫正前摄像头xx的失真向量

        - R_xx：3x3 （外部）的旋转矩阵(从相机0到相机xx)

        - T_xx：3x1 （外部）的平移矢量(从相机0到相机xx)

        - S_rect_xx：1x2  矫正后的图像xx的大小

        - R_rect_xx：3x3  纠正旋转矩阵(使图像平面共面)

        - P_rect_xx：3x4  矫正后的投影矩阵
（内参矩阵，前面第一行为前面四个数据，依次三行）

    （2）calib_velo_to_cam.txt主要是得到点云到图像的旋转平移矩阵
        - R：3x3旋转矩阵

        - T：3x1平移向量

        - delta_f：弃用

        - delta_c：弃用
        - Tr_velo_to_cam= （R | T）（点云到相机的外参矩阵3x4）
        
     （3）calib_imu_to_velo.txt
         Y = P_rect_xx *
         R_rect_00 * (R|T)_velo_to_cam * (R|T)_imu_to_velo * X
         
  摄像头文件：image_00到image_03四个文件夹，分别对应4个摄像头，常用的摄像头为02
  点云文件：雷达扫描到的点文件，velodyne_points文件夹，其中包括多个bin文件和时间戳文件
  
  
  关于数据预处理和LSTM网络框架，这个是对文字的处理，可以借鉴（https://zhuanlan.zhihu.com/p/42084721）
  
  # 0323
  data/KITTI/kitti_utils.py 完成数据预处理，生成.tfrecord 文件
  data/KITTI/generate_kitti_train_datasets.py  按照TXT文件里的列表，批量进行数据预处理，批量生成.tfrecord文件
  
  # 0324-0329
  1、修改代码，进行模型的评估。
  2、进一步了解TensorFlow几个重要函数的用法。
  3、利用TensorBoard，生成深度预测的图像，查看结果。
  4、完成中期检查表，准备中期答辩

  ## ~~~
  # 0330
  中期答辩，修改中期论文，梳理了一下接下来的工作。四月十号前完成代码修改，评估和训练很耗实践，需要留出充足时间。
  
  # 0331
  1、阅读文献
   Eigen, D., Puhrsch, C., & Fergus, R. (2014). Depth map prediction from a single image using a multi-scale deep network. In Advances in Neural Information Processing Systems (pp. 2366-2374). 
   参考论文中使用到的预处理和loss的计算方法和这篇文献的一样。
   2、看懂开源代码的loss计算部分
   
  # 0402
  今天终于把loss改完了，没想到网络输出的深度不是深度本度，是深度的倒数
  loss收敛~
  
  # 0404
  修改完模型，
  但是，由于源代码输入的数据为四维，少了timestep，我强行增加了一维，暂时将其设置成为1，
  还没搞明白的：1、timestep=num_views？
               2、可能要在预处理阶段修改，如何改？
  
  # 0405
  今天开始看预处理部分
  光是第一步， We use 56 scenes from the “city,” “residential,” and “road” categories of the raw data.就看了半天= =、
  找不到数据有这几种分类，
  翻墙到官网之后才看到，原始数据分为 ’Road’, ’City’, ’Residential’, ’Campus’ 和’Person’五类，可以在官网查看分类信息，
  然后手动= =、编写了训练集和测试集的列表
  
  # 0406-0413
  完成代码修改，开始训练
  开始写报告

  # 0413
  
  修改神经网络:
  1.在解码部分的卷积层和反卷积层后加上batch nomalization
  
  2.在构建模型时取消原先的先将输入图像数据切片再进入神经网络。直接将数据传入神将网络，timestep改为3。解码阶段切边处理，将切片后五维的数据squeeze至四维，再分别进行反卷积和卷积操作。最后concat结果
              
  问题：训练两小时后LOSS降至最小值，不再下降，但是预测结果并不是很好
  
  论文部分：完成第一部分绪论
  
  # 0414 -0417
  完成论文第二章基于深度学习的深度估计及论文第三章的第一部分网络结构
  调整网络及参数进行训练
  
  但是因为加上了batch nornalization，训练两个小时左右，loss值能够收敛
  但是训练得到的结果十分差，基本上没有细节，模型还需要调整
  
  # 0418-0419
  1、论文：完成三分之一
  2、模型：这几天一直在不断训练和调整，
          按照论文中BN仅加在Conv和Deconv之后，
          对解码阶段进行修改，原来是：concat（逆卷积，对应ConvLSTM输出）->做卷积
          修改后：concat（逆卷积，对应输出的卷积）->为了维度一致再卷积（concat后channels的总数翻倍）
          

  # 0420-0422
  1、论文：写完第三部分loss，还剩：预处理，实验结果，总结。
  
  2、代码：按照原来的形式，增加解码阶段层数，训练大约八小时后，效果不好
          修改为deconv+concat+conv形式，训练后，深度图缺少细节
          
  
  # 0423
  修改模型，上一次的结果没有细节，所以把前两层ConvLSTM的滤波器大小减小了，改为3*3，运行后的结果有细节，能看到数目，电线杆的轮廓
  论文：完成前三章的初稿
  
  # 0424-0425
  经过老师提醒，检查loss函数是否正确，发现tf.log(inf)并没按照预想的为inf而是一个真实的数值，修改loss函数后，深度预测的效果并没有得到很大的提升，而且loss收敛得很快的问题依然存在
  我发现将time steps的数值增大为10后，效果得到明显的提升
  论文部分：完善前三章的内容，修改格式
  
  # 0426-0427
  ![image](https://github.com/Fengqiqif77/Implementation-of-depth-estimation-algorithm/blob/master/结果/loss%2Bl2.png)
  l2的系数取为0.005是因为反卷积和卷积的权重为0.005
  删掉l2后，losses下降的趋势没有变，只是波动会更大，收敛的速度更快
  
  删去l2，训练五个小时后的深度预测结果：（loss还在下降）能够看出远近关系，但是缺少细节
  
  
  ![image](https://github.com/Fengqiqif77/Implementation-of-depth-estimation-algorithm/blob/master/结果/d2.png)
  est_depth
  
  
  ![image](https://github.com/Fengqiqif77/Implementation-of-depth-estimation-algorithm/blob/master/结果/gt2.png)
  gt_depth
  
  # 0428
  step%1000=0时能够存储est和gt
  
  按照真实深度图的原尺寸生成训练集
  
  # 0429-0430
  取昨天存的图片检验损失函数
  
  首先发现计算式的分母n，应该取gt的有效值，我取成了相减后的有效值
  
  然后没有对在gt中有效，但是在est中无效部分进行处理
  
  修改了这些地方后，训练
  
   ![image](https://github.com/Fengqiqif77/Implementation-of-depth-estimation-algorithm/blob/master/结果/d3.png)
   est
   
   ![image](https://github.com/Fengqiqif77/Implementation-of-depth-estimation-algorithm/blob/master/结果/img3.png)
    image
    
  # 0501
    修改loss，
    
    运用[快速深度补全]https://github.com/kujason/ip_basic 的算法对训练集的图像深度补全，然后预处理，生成.tfrecord
    
    论文：1、完成摘要
    
          2、补充关于深度补全的部分
          
          3、完成实验结果中目前能写的部分
          
          4、整理参考文献的顺序

  # 0502
  运行评估文件的脚本，报错：缺少zlib，libpng，png++等库
  
  成果安装zlib，png++，按时libpng一直不能成功导入

  # 0503-0507
  成功运行评估的脚本文件
  
  完成大尺寸图片的训练
  
  # 0508-0509
  完成论文
  用免费的查重软件查重，根据查重结果修改论文
