# 周报  

## 一、放假至1月12日  

  + 主要工作内容与成果：  
  
                    1、完成开题报告与任务书  
  
                    2、翻译参考文献  
                    
                    3、查阅资料，了解学习相关知识

## 二、1月12日至2月9日
   
   + 主要工作与成果：
             
                1、学习了有关深度学习的深度优化、梯度、神经网络的基本知识

                2、了解CNN的经典架构，及他们之间的优劣
 
                3、了解深度学习软件的框架，重点学习了PyTorch的相关知识

   + 下一步工作计划：

                继续学习RNN的相关知识，用PyTorch搭建一个小框架熟悉python语言
              
## 三、2月9日至2月16日

  + 主要工作与成果：
  
             安装pytorch
             
  + 遇到的的问题：
   
              1、直接安装pytorch速度慢，好几次中途停止，安装失败
              
              2、利用清华源镜像安装，速度稍微快一些，但是由于网速较慢，总是发生HTTP的报错，重试几次后终于安装成果
              
              3、不能成功导入torch包
                 （电脑上有两个版本的python，pytorch只支持3以上版本，将python2.7卸载后，成功导入torch）
                 
               4、torch.cuda报错（没有实现安装驱动）
               
## 四、2月17至3月1日

  + 主要成果：安装cuda及cuDNN
  
  + 遇到问题：1、CUDA driver version is insufficient for CUDA runtime version
                原因：CUDA驱动版本不满足CUDA运行版本。
                
 # 0302
 
   有了较为明确的中期目标，感觉更有动力了
   连接上了实验室的服务器，fighting
   
 # 0303
 
   看新论文和代码，有点懵
   
 # 0305
   重新看了下convLSTM的论文，和新论文做了下对比，我要实现的方法应该就是被称作encoderlstm的模型
   
   [convlstm] (https://www.dazhuanlan.com/2019/10/01/5d92fff8b9457/)
   
   补了下encoder-decoder网络结构的知识
   
   [encoder-decoder] (https://blog.csdn.net/xbinworld/article/details/54605408)
   
  # 0306
  认真学习了一下Dispnet网络相关知识
  （https://blog.csdn.net/kongfy4307/article/details/75212800）
  
  看开源代码，主要仔细看了encoderlstm的模型
  
  slim.arg_scope  设置参数
  
  slim.conv2d 做卷积（输入图像，滤波器个数，滤波器大小，步长，范围）
  cnv1  = slim.conv2d(current_input, 32,  [3, 3], stride=2, scope='cnv1')
  torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')

   # 0307
 无法导入torch包，最开始一直以为是路径配置的问题，弄了好久，后面问了老师才知道是没有激活环境的原因
 进入虚拟环境TestEnv后，输入source activate TestEnv
 激活环境之后，成功导入torch包啦~~

  # 0308
  今天先看了两篇论文，今天觉得我要实现的网络和encoderlstm还是有区别，询问学姐后确定他们两个不是完全一样的
  本来准备直接开始修改代码，发现自己的预备知识还是不足，修改起来很费劲
  所以先跑了几遍手写数字识别的网络来熟悉深度学习网络的框架，网上教程挺多的，基本上没有遇到什么困难，
  然后，我找到两份分别由pytorch和tensorflow写的代码，做比较
  
  # 0309
  今天是周一，需要开会，开会确定了未来一周的工作
  然后建立了新的虚拟环境
  
  # 0310
  安装好需要的包，
  运行手写识别数字程序发现，虽然可以成功导入tensorflow，但是却无法按照官网的教程成功下载minist，导入其他tensorflow内的包时内会报错
  上网查了下后，发现是tensorflow高版本2.0版缺少一些文件，导致导入失败，卸载高版本，重新安装低版本后，问题解决
  但是，运用matplotlib绘图时，图片并不会显示
  
  
  # 0311
  今天先直接跑了下开源代码，warning太多，而且有报错
  于是开始解决昨天的，显示图片问题
  网上的大多数解决方案都是针对远程服务器的GUI界面显示在本地的，
  针对没有图形界面服务器，网上给出的解决方案是将绘制好的图片存储到指定路径，然后打开图片查看
  
  同样，我还是用手写数字识别的网络进行测试，成功得到了一张图片
  
  但是总觉得这些改动很奇怪，而且每次都这样操作的话，很麻烦，
  继续查资料后发现，这个方法将matplotlib后端改成AGG，强制不能交互式查看图片，只能将图片保存后查看
  我将新加的代码注释后，直接使用plt.show()图片就显示出来了？？！！那我昨天遇到的问题是咋回事？
  ：
 
  # 0313
  下载KITTI训练集，训练和测试这两者的区别和功能不是很清楚，乘着下载训练集的时候，看了资料，了解了两者的作用
  在真正运行代码前还需要对数据进行预处理，
  开源代码中已有预处理的代码
  
  # 0314 
  昨天训练集没有下完，今天接着下
  然后看了下代码运行后的报错和warning，
  大多数warning都是某某库已弃用，请换用新库，使用tensorflow2.0版本，但是由于需要和服务器cuda版本一致，所以还是继续沿用1.x版本
  
  然后在和媛媛讨论的时候，发现她遇到一个和我一样的报错，dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/lib64
后面发现，我们安装的tf缺少了部分包，导致报错，卸载tf后重新安装，安装包齐全，没有再报错

训练集是直接从学姐那里拷贝到自己的虚拟环境中，但是总在拷贝过程中中断

再次修改文件路径后运行开源代码，报错，tensorflow.python.framework.errors_impl.PermissionDeniedError: /playpen1; Permission denied
没有写入权限的报错，查看代码后发现是训练的时候报错。修改该部分的路径，从相对路径改为绝对路径，再次运行，没有报错

## ~~~
# 0317
代码能跑起来，但是GPU占有率非常低才有个位数的占有率，最终输出的结果也全为0
暂未解决= =、

  
  
  
